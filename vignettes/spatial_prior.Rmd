---
title: "Spatial priors in shinymrp"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Spatial priors in shinymrp}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```


Conditional Autoregressive (CAR) models are commonly used to represent local dependency between random variables. We provide two popular members of this family of models as priors for our hierarchical models:

- Intrinsic CAR (ICAR): an intrinsic (improper) Gaussian Markov random field that smooths by penalizing neighbor differences
- BYM2: a reparameterization of the BYM (Besag-York-Mollié) model that combines a structured ICAR component with a spatially independent component and incorporates scaling to standardize interpretation across graphs.

## Areal data & neighborhood graph
<!-- Alex Jiang : for queen contiguity, two areal units are considered as neighbors as long as they share a vertex -->
These models specifically apply to *areal data*, which consist of a single aggregated measure for each areal unit. In spatial modeling, the primary interest lies in the **relationships between units** rather than in the units themselves. Common approaches to define these relationships include **rook** and **queen contiguity**, which identify two areal units as neighbors if they share a border (or a vertex). We use the `spdep` package to construct neighborhood graphs from areal units. For ZIP codes, **ZCTAs** (ZIP Code Tabulation Areas) are used as proxies to infer the adjacency structure. A common mathematical representation of this structure is the **adjacency matrix**, denoted \( \mathbf{W} \). Because the edges are undirected, \( \mathbf{W} \) is an \( N \times N \) symmetric matrix for a set of \( N \) areal units. This representation enables mathematical operations that yield valuable insights into the neighborhood graph, as will be illustrated in later sections.

The **connectivity** of the graph can affect the choice of spatial model. For instance, the ICAR prior requires a connected graph. A **connected** graph contains a single **component**, meaning that each node can be reached from any other node. Conversely, a graph with multiple components is **disconnected**, as nodes in one component cannot reach those in another. A component of size one is referred to as an **island** (or **isolate**). Since the structured component of a spatial model relies on neighborhood edges for smoothing, these isolates require special handling. 
<!-- Alex Jiang : Added a paragraph about multiple components -->
Throughout, we assume that the adjacency graph is connected, i.e., it consists of a single component. This ensures that the graph Laplacian $\mathbf{L}$ has rank $N-1$ and that a single sum-to-zero constraint suffices for identifiability.
Cases involving disconnected graphs—where $\mathbf{L}$ has multiple null-space dimensions—require separate ICAR components for each connected subgraph; these are discussed in Section Handling disconnected graphs with multiple ICAR components.

## Intrinsic Conditional Auto-Regressive (ICAR) models
<!-- Alex Jiang : it is more rigorous to write the probability of \phi without directly using L, as the graph Laplacian is singular, I recommend using the following exponential quadratic form. Also, ICAR is not necessarily multivariate normal, as the prior is improper. I rephrased the wording a little bit. -->

The **ICAR model** is a special case of a Gaussian Markov random field (GMRF), known as the intrinsic GMRF. Let $ \pmb{\phi} = \left(\phi_1, \ldots, \phi_N\right)^{\top} $ denote the spatial random effects associated with the $N$ neighboring regions from an ICAR model. Under the assumption that spatial dependence is fully captured by the neighborhood structure in $\mathbf{W}$, the ICAR model defines the joint distribution of \( \pmb{\phi} \) as: Each $\phi_i$ is conditionally distributed based its neighboring values: 

\[
\phi_i \mid \phi_{-i} \sim {N}\!\left(
  \frac{\sum_j w_{ij}\phi_j}{\sum_j w_{ij}},
  \frac{1}{\tau \sum_j w_{ij}}
\right),
\]

where $w_{ij} > 0$ if nodes $i$ and $j$ are neighbors and $w_{ij} = 0$ otherwise, and $\tau$ controls the precision and overall smoothness. Thus, the joint improper density can be written as 

\[ p(\pmb{\phi} \mid \tau ) \propto \tau^{\frac{N-1}{2}}\exp \left(-\frac{\tau}{2} \pmb{\phi}^{\top} \mathbf{L} \pmb{\phi}\right), \]

where \( \mathbf{L} = \mathbf{D} - \mathbf{W} \) is the **graph Laplacian matrix**, constructed from the adjacency matrix $\mathbf{W}$ and the degree matrix $\mathbf{D}$, where $\mathbf{D} = \text{diag}(d_i)$ with $d_i = \sum_j w_{ij}$. Note that $\mathbf{L}$ satisfies $\mathbf{L} \mathbf{1}=\mathbf{0}$, and is positive semidefinite but not invertible. Expanding the quadratic form, we can express the log-probability density in terms of the pairwise differences between neighboring pairs:  

\[ \log p(\pmb{\phi}) = -\frac{\tau}{2} \sum_{i \sim j} w_{ij} (\phi_i - \phi_j)^2 + \text{const.}, \]

where ${i \sim j}$ means that $i$ and $j$ are neighbors. Its joint density is improper, but characterizes local conditional relationships among neighboring sites and penalizes large differences between neighbors, thereby encouraging local smoothness. Also, note that the precision parameter $\tau$ controls the degree of smoothness the ICAR component is able to capture. This formulation explicitly shows how the neighborhood structure is incorporated into the joint probability. It also reveals the **non-identifiability problem** of the ICAR model, which arises because adding a constant to all elements of \( \pmb{\phi} \) does not change the differences. To resolve this, a **sum-to-zero constraint** is imposed: \[ \sum_{i=1}^{N} \phi_i = 0 \] This constraint also prevents \( \pmb{\phi} \) from confounding the model intercept.

### Stan implementation

The implementation in Stan is straightforward with the pairwise difference fomulation.

Function for computating the log probability density

``` stan
functions { 
  real icar_normal_lpdf(vector phi, array[] int node1, array[] int node2) {
    return -0.5 * dot_self(phi[node1] - phi[node2]);
  }
  ...
```
Pass neighborhood information using edges defined by node indices

``` stan
data {
  int<lower = 0> N;  // number of areal regions
  int<lower = 0> N_edges;  // number of neighbor pairs
  array[N_edges] int<lower = 1, upper = N> node1;
  array[N_edges] int<lower = 1, upper = N> node2;
  ...
```

Use Stan’s built-in sum_to_zero_vector to constrain phi

``` stan
parameters {
  sum_to_zero_vector[N] phi; // structured spatial random effects
  ...
```

Add to joint probability density using Stan’s distribution statement

``` stan
model {
  phi ~ icar_normal(node1, node2);
  ...
```

## BYM2 model
<!-- Alex Jiang :  I expanded a bit on what you meant by complete spatial correlation). Also, the definition of the scaling factor is usually its reciprocal -- I kept our current version to align with the code.--->
While the ICAR prior provides a convenient way to encode spatial dependence, it can be overly restrictive in practice. By construction, all variation in $\pmb{\phi}$ is spatially structured, so independent region-specific deviations are absorbed into the smooth surface. In many real datasets, however, some variability is spatially uncorrelated (e.g., due to measurement error or region-specific effects). To address this, the Besag–York–Mollié (BYM) model augments the ICAR component with an unstructured random effect that captures independent noise. The BYM2 reparameterization (Riebler et al., 2016) further refines this approach by standardizing the ICAR term and separating overall scale from spatial structure. In effect, the precision parameter $\tau$ from the ICAR model is replaced by a fixed scaling constant derived from the neighborhood graph, ensuring that the total variance and spatial proportion parameters remain interpretable and comparable across datasets.

In the BYM2 formulation, the ICAR precision matrix is rescaled by \(s\), computed from the graph Laplacian \(\mathbf{L}\) as

\[
s = \left\{ \operatorname{mean}\!\big[\mathrm{diag}(\mathbf{L}^{-}_{\text{pseudo}})\big] \right\},
\]

where \(\mathbf{L}^{-}_{\text{pseudo}}\) denotes the Moore–Penrose inverse of the Laplacian.  
This ensures that the scaled ICAR component \(\pmb{\phi}^\ast = s^{-1/2}\pmb{\phi}\) has unit marginal variance under the graph structure, i.e. \(\operatorname{Var}(\phi_i^\ast) = 1\).

The spatial random effect for region \(i\) is then modeled as

\[
b_i
= \sigma\!\left(
  \sqrt{\rho}\,\phi_i^\ast
  + \sqrt{1-\rho}\,\theta_i
\right) = \sigma\!\left(
  \sqrt{\frac{\rho}{s}}\,\phi_i
  + \sqrt{1-\rho}\,\theta_i
\right)
\qquad i = 1, \dots, N,
\]

where:

- \(\phi_i^\ast\) is the *scaled* ICAR component, standardized such that \(\operatorname{Var}(\phi_i^\ast) = 1\);
- \(\theta_i \sim \mathbf{N}(0,1)\) is the unstructured (independent) term;
- \(\sigma > 0\) is the overall standard deviation controlling total variability; and
- \(\rho \in [0,1]\) controls the proportion of variation attributed to the structured (ICAR) component.

This formulation removes the precision parameter \(\tau\) from the model by absorbing it into the scaling of the ICAR component. As a result, the parameters \(\sigma\) and \(\rho\) have clear and interpretable meanings:  
\(\sigma\) represents the total spatial variability, and \(\rho\) quantifies the proportion of that variability explained by spatial structure.


### Stan implementation for connected graph

We can use the implementation of the ICAR component in the previous section.

``` stan
functions { 
  real icar_normal_lpdf(vector phi, array[] int node1, array[] int node2) {
    return -0.5 * dot_self(phi[node1] - phi[node2]);
  }
  ...
```
Pass the scaling factor computed from the adjacency matrix in addition to the edgelist

``` stan
data {
  int<lower = 0> N;  // number of areal regions
  int<lower = 0> N_edges;  // number of neighbor pairs
  array[N_edges] int<lower = 1, upper = N> node1;
  array[N_edges] int<lower = 1, upper = N> node2;
  real<lower=0> scale_factor;
  ...
```

Use Stan’s built-in sum_to_zero_vector to constrain phi

``` stan
parameters {
  real<lower=0> sigma; // overall standard deviation for spatial effect
  real<lower=0, upper=1> rho; // mixing parameter 
  vector[N] theta; // unstructured spatial random effect
  sum_to_zero_vector[N] phi; // structured spatial random effect
  ...
```

Compute combined spatial effect

``` stan
transformed_parameters {
  vector[N] b = sqrt(rho ./ scale_factor) * phi + sqrt(1 - rho) * theta
  ...
```

Assigning priors

``` stan
model {
  theta ~ std_normal();
  phi ~ icar_normal(node1, node2);
  rho ~ beta(0.5, 0.5)
  sigma ~ std_normal();
  ...
```


### Handling Disconnected Graphs with Multiple ICAR Components

The standard BYM2 model assumes that the spatial graph is **connected**, meaning every areal unit can be reached from any other through a path of neighboring edges.  
When the adjacency graph has **multiple connected components**, the Laplacian matrix \(\mathbf{L}\) becomes block-diagonal, and the ICAR prior exhibits one degree of freedom (a zero eigenvalue) **per component**.  
Consequently, the BYM2 formulation must be extended to handle these multiple components.

Following Freni-Sterrantino et al. (2018), the generalization proceeds as follows.

---

#### 1. Identify connected components

Suppose the graph consists of \(K\) disjoint components, with index sets  
\(\mathbf{C}_1, \ldots, \mathbf{C}_K\) such that  
\(\bigcup_{k=1}^K \mathbf{C}_k = \{1,\ldots,N\}\) and  
\(\mathbf{C}_k \cap \mathbf{C}_\ell = \emptyset\) for \(k\neq\ell\).

Each component has its own Laplacian submatrix \(\mathbf{L}_k\) and adjacency submatrix \(\mathbf{W}_k\).

---

#### 2. Compute per-component scaling factors

For each component \(k\), compute its scaling factor \(s_k\) analogously to the connected case:

\[
s_k = \operatorname{mean}\!\big[\mathrm{diag}(\mathbf{L}_{k,\text{pseudo}}^{-})\big],
\]

where \(\mathbf{L}_{k,\text{pseudo}}^{-}\) is the Moore–Penrose inverse of \(\mathbf{L}_k\).  
This ensures that the standardized ICAR field within component \(k\),

\[
\pmb{\phi}_k^\ast = s_k^{-1/2}\pmb{\phi}_k,
\]

has \(\operatorname{Var}(\phi_{i}^\ast)=1\) for all \(i\in \mathbf{C}_k\).

---

#### 3. Define the BYM2 prior within each component

For all nodes \(i \in \mathbf{C}_k\) belonging to component \(k\) of size \(n_k>1\), assign

\[
b_i
= \sigma\!\left(
  \sqrt{\rho}\,\phi_i^\ast
  + \sqrt{1-\rho}\,\theta_i
\right)
= \sigma\!\left(
  \sqrt{\tfrac{\rho}{s_k}}\,\phi_i
  + \sqrt{1-\rho}\,\theta_i
\right),
\]
with  
\(\pmb{\phi}_k \sim \text{ICAR}(\mathbf{L}_k)\),  
\(\theta_i \sim \mathbf{N}(0,1)\),  
and the same global parameters \(\sigma>0\) and \(\rho \in [0,1]\) shared across components.

---

#### 4. Handle singleton nodes (“islands”)

If a component consists of a **single node** (\(n_k=1\)), there are no spatial neighbors and thus no structured term.  
In that case, the spatial effect reduces to a pure unstructured random effect:

\[
b_i = \sigma\,\theta_i, \qquad \theta_i \sim \mathbf{N}(0,1).
\]

This prevents isolated regions from inheriting artificial structure.

---

#### 5. Impose per-component constraints

Because each sub-Laplacian \(\mathbf{L}_k\) has one zero eigenvalue, a **sum-to-zero constraint** must be applied within every connected component:

\[
\sum_{i \in \mathbf{C}_k} \phi_i = 0,
\qquad  k = 1, \ldots, K.
\]

This ensures identifiability and removes the constant-shift indeterminacy of each ICAR block.

---

#### 6. Compact matrix representation

Stacking all components, the full structured term \(\pmb{\phi}\) satisfies

\[
p(\pmb{\phi})
\propto
\exp\!\left(
  -\tfrac{1}{2}
  \sum_{k=1}^K
  s_k^{-1}\pmb{\phi}_k^{\top}\mathbf{L}_k\pmb{\phi}_k
\right),
\]
with independent sum-to-zero constraints for each \(k\).

The complete BYM2 prior for disconnected graphs can then be expressed as

\[
\mathbf{b}
= \sigma\!\left(
  \sqrt{\rho}\,\mathbf{S}\,\pmb{\phi}
  + \sqrt{1-\rho}\,\pmb{\theta}
\right),
\]
where \(\mathbf{S}=\mathrm{diag}(s_1^{-1/2},\ldots,s_K^{-1/2})\) scales each component appropriately.

---

This extension allows the BYM2 prior to accommodate graphs containing multiple connected regions or isolated nodes without distorting the global scale or over-shrinking small components.


### BYM2 reparameterization for disconnected graph

To make the implementation of this extension easier, we reparameterize, at the component level, the structured ICAR field on a basis that (i) lies in each component’s sum-to-zero subspace and (ii) is BYM2-standardized. Isolates get no structured variance and only receive the spatially independent part.

Consider a single connected neighborhood graph with \(N\ge2\) areas. Let \(A\) be the symmetric adjacency, \(D=\mathrm{diag}(d_i)\) the degree matrix, and \(L=D-A\) the graph Laplacian. Because the graph is connected, \(L\mathbf 1=0\) and \(\mathrm{null}(L)=\mathrm{span}\{\mathbf 1\}\). The intrinsic CAR prior has log-density \(-\tfrac12\,\phi^\top L\,\phi\); it is improper on \(\mathbb R^N\) but becomes proper on the sum-to-zero subspace
\[
\mathbf H=\{\phi\in\mathbb R^N:\mathbf 1^\top \phi=0\}.
\]

Since \(L\) is symmetric positive semidefinite, diagonalize \(L=U\Lambda U^\top\) where the eigenvalues satisfy \(0=\lambda_1<\lambda_2\le\cdots\le\lambda_N\), with \(u_1\propto \mathbf 1\). Write \(U_+=[u_2,\ldots,u_N]\in\mathbb R^{N\times(N-1)}\) and \(\Lambda_+=\mathrm{diag}(\lambda_2,\ldots,\lambda_N)\). The Moore–Penrose pseudoinverse is
\[
L^{+}=U_+\Lambda_+^{-1}U_+^\top,
\]
which equals the covariance of the ICAR prior restricted to \(\mathbf H\).

Define the basis
\[
R \;=\; U_+\,\Lambda_+^{-1/2}\in\mathbb R^{N\times(N-1)},\qquad \eta \sim \mathbf N(0,I_{N-1}),\qquad \phi \;=\; R\,\eta.
\]
This reparameterization is equivalent to the constrained ICAR in the following sense. First, the support matches because each column of \(R\) is orthogonal to \(\mathbf 1\), hence \(\mathbf 1^\top\phi=\mathbf 1^\top R\eta=0\) for all \(\eta\), i.e., \(\phi\in\mathbf H\). Second, the mean matches since \(\mathbb E[\phi]=R\,\mathbb E[\eta]=0\). Third, the covariance matches because
\[
\mathrm{Var}(\phi) \;=\; R\,\mathrm{Var}(\eta)\,R^\top \;=\; R R^\top \;=\; U_+\Lambda_+^{-1}U_+^\top \;=\; L^{+}.
\]
Linear images of a multivariate normal are normal; therefore \(\phi\stackrel{d}{=}\mathbf N(0,L^{+})\) on \(\mathbf H\). Right-orthogonal rotations of the scores, \(R\mapsto RQ\) with \(Q\) orthogonal, leave \(R R^\top\) unchanged; the parameterization is not unique but the induced law for \(\phi\) is.

BYM2 standardization rescales the structured field so that the geometric mean of its marginal variances equals one. Let \(v_i=(L^{+})_{ii}\) and define
\[
s \;=\; \exp\Big(\tfrac{1}{N}\sum_{i=1}^N \log v_i\Big),\qquad R_{\text{BYM2}} \;=\; \frac{1}{\sqrt{s}}\,R,\qquad \tilde\phi \;=\; R_{\text{BYM2}}\,\eta.
\]
Then \(\mathrm{GM}\big(\operatorname{diag}\mathrm{Var}(\tilde\phi)\big)=1\), while \(\mathbf 1^\top \tilde\phi=0\) still holds because the subspace is unchanged.


### Stan implementation for both connected and disconnected graphs
The reparameterization allows more cleaner implementation as the reduced-rank ICAR basis is already BYM2-standardized and enforces the sum-to-zero constraint by construction. The sum_to_zero vector is not longer needed which can improve sampling.

Pass the scaled reduced-rank ICAR basis

``` stan
data {
  int<lower=0> N;  // number of areal regions
  int<lower=0> N_pos;
  matrix[N_zip, N_pos] R; // already scaled so that geometric mean of
                          // marginal variance is 1
  ...
```

``` stan
parameters {
  real<lower=0> sigma; // overall standard deviation for spatial effect
  real<lower=0, upper=1> rho; // mixing parameter 
  vector[N] theta; // unstructured spatial random effect
  vector[N] eta; // structured reduced-rank scores
  ...
```

Compute the scaled ICAR component and combined spatial effect

``` stan
transformed_parameters {
  vector[N] phi = R * eta;
  vector[N] b = sqrt(rho) * phi + sqrt(1 - rho) * theta
  ...
```

Assigning priors

``` stan
model {
  eta ~ std_normal();
  theta ~ std_normal();
  sigma ~ std_normal();
  ...
```

## Case study: COVID Infection Mapping

One of the major applications of the BYM2 model is infectious disease surveillance. In this case study, we fit a multilevel regression model to a dataset containing COVID-19 test records from Michigan Medicine hospital. This relatively large dataset includes over 120,000 test records from patients residing throughout Michigan and neighboring states. The dataset spans over 1,000 ZIP codes, with most records coming from areas surrounding Michigan Medicine. As a result, more than a quarter of the ZIP codes have five or fewer test records. The BYM2 model helps stabilize estimates in these sparsely observed ZIP codes by partially pooling information from neighboring areas.

```{r, echo=FALSE, out.width="100%"}
knitr::include_graphics("./figures/sample_size_map.png")
```

Let's denote the test result for individual $i$ as $y_i$, where $y_i=1$ indicates a positive result and $y_i=0$ indicates negative. We obtain aggregated counts as the number of tests $n_j$ and the number of positive cases $y^*_j$ in cell $j$. Let $p_j=\textrm{Pr}(y_{j[i]}=1)$ be the probability that person $i$ in cell $j$ tests positive. We account for the PCR testing sensitivity and specificity, where the positivity $p_j$ is a function of the test sensitivity $\delta$, specificity $\gamma$, and the true incidence $\pi_j$ for people in cell $j$:

\begin{align}
\label{positivity}
p_j=(1-\gamma)(1-\pi_j )+\delta \pi_j.
\end{align}

We fit a binomial model for $y^*_j$, $y^*_j \sim \textrm{binomial}(n_j, p_j)$ with a logistic regression for $\pi_j$ with covariates---sex, age, race, ZIP codes, and time in weeks---to allow time-varying incidence in the multilevel model.
\begin{align}
\label{pi}
\textrm{logit}(\pi_j)=\beta_1+\beta_2{\rm male}_j+\alpha_{{\rm a}[j]}^{\rm age}+\alpha_{{\rm r}[j]}^{\rm race}+\alpha_{{\rm s}[j]}^{\rm ZIP}+\alpha_{{\rm t}[j]}^{\rm time},
\end{align}
where ${\rm male}_j$ is an indicator for men; ${\rm a}[j]$, ${\rm r}[j]$, and ${\rm s}[j]$ represent age, race, and ZIP levels; and ${\rm t}[j]$ denotes the time in weeks when the test result is collected for cell $j$.

We assign the hierarchical priors to the varying intercepts: 
\begin{align}
\nonumber &\alpha^{\rm age} \sim \mbox{normal}(0,\sigma^{\rm age} ), \,\,\, \sigma^{\rm age}\sim \mbox{normal}_+ (0,2.5)\\
&\alpha^{\rm race} \sim \mbox{normal}(0,\sigma^{\rm race} ), \,\,\, \sigma^{\rm race}\sim \mbox{normal}_+ (0,2.5).\\
\alpha_{\rm s}^{\rm ZIP} &= \sigma^{\rm ZIP} \, \mathbf{b}, \,\,\, \sigma^{\rm ZIP} \sim \mbox{normal}_+ (0,2.5),
\end{align}

where \(\mathbf{b}\) is the combined spatial effect defined in the BYM2 model section.

The model can be specified straightforwardly using `shinymrp`. See the reference page for parameter descriptions.

```{r eval=FALSE}
library(shinymrp)

# Initialize workflow
workflow <- mrp_workflow()

# Preprocess sample data
# ...

# Construct poststratification table
# ...

# Create a new model object
model <- workflow$create_model(
  intercept_prior = "normal(0, 5)",
  fixed = list(
    sex = "normal(0, 2.5)",
    urbanicity = "normal(0, 2.5)",
    college = "normal(0, 2.5)",
    employment = "normal(0, 2.5)",
    poverty = "normal(0, 2.5)",
    income = "normal(0, 2.5)",
    adi = "normal(0, 2.5)"
  ),
  varying = list(
    race = "normal(0, 2.5)",
    age = "normal(0, 2.5)",
    time = "normal(0, 2.5)",
    zip = "bym2"
  ),
  sens = 0.7,
  spec = 0.999
)

# Run MCMC
model$fit(
  n_iter = 4000,
  n_chains = 4,
  seed = seed,
  adapt_delta = 0.95
)
```

We fit the model using Stan's Monte Carlo Markov Chain algorithm with 4,000 iterations across 4 chains to approximate the posterior distributions. Model fitting took approximately 8.5 hours—about one hour longer than a model treating ZIP codes as independent. This additional computational cost reflects both the more complex posterior geometry and the matrix multiplications involving the spatial adjacency structure required at each iteration.

```{r, echo=FALSE, comment=""}
qs2::qs_read("data/spatial_prior/summary.qs2")
```


The posterior samples for the spatial proportion parameter concentrates near high values, indicating that spatially structured effect plays a more dominant role than its counterpart.

```{r, echo=FALSE, comment=""}
read.csv("data/spatial_prior/loo_compare.csv")
```

To validate the presence of spatial structure and assess the BYM2 model's ability to capture it, we fit a comparison model with spatially independent ZIP code effects and evaluated predictive performance using leave-one-out cross-validation (LOO-CV). The negative `elpd_diff` indicates that the BYM2 model achieves higher expected log predictive density. Moreover, the difference is large relative to its standard error ,`se_diff`, providing strong evidence that incorporating spatial dependence substantially improves out-of-sample predictive accuracy.

# References

- Besag, J. (1974). Spatial interaction and the statistical analysis of lattice systems. Journal of the Royal Statistical Society: Series B (Methodological), 36(2), 192-225.
- Riebler, A., Sørbye, S. H., Simpson, D., & Rue, H. (2016). An intuitive Bayesian spatial model for disease mapping that accounts for scaling. Statistical methods in medical research, 25(4), 1145-1165.
- Freni-Sterrantino, A., Ventrucci, M., & Rue, H. (2018). A note on intrinsic conditional autoregressive models for disconnected graphs. Spatial and spatio-temporal epidemiology, 26, 25-34.

